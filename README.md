<div class="page" title="Page 5">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 24.000000pt; font-family: 'Economica'; font-weight: 700;">INTRODUCTION&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Identification of malignant from normal cells from microscopic images is very difficult because morphologically both types of cells appear similar. They are also very expensive and not widely available. Usually cancer cells are detected in advanced stages using microscopic images because of the medical expertise as those malignance cells are present in a much greater number as compared to normal people. Therefore, it is very important to detect those cells at an early stage for better cure and improving the survival of the subject. This is where cell classification via image processing comes into play to provide a solution which can be deployed easily at lesser cost.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Image classification models are proving to be very helpful in cancer cell detection problems. However, imaging processing models require very large datasets in order to obtain good results, which means expensive computation is required. This is where Apache Sparks comes into play. As a framework for distributed computation, Spark will allow us to build deep learning models which are very computationally heavy. There are many ways to do Deep learning with Apache Spark. These methods go from distributed DL with Keras and Pyspark, to Tensorflow on Spark or bigDL. In this project we will discuss the different methods that exist nowadays to work with deep learning models in Spark and we will implement some of these methods to see how they vary from each other.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">For this project we will store the data in an Amazon Web Series S3 bucket and we will use Spark in two different platforms, one will be in an EMR cluster and the second will be using Amazon Sagemaker. All of these technologies mentioned will be explained in detail in the project.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">5&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 6">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 24.000000pt; font-family: 'Economica'; font-weight: 700;">State of the Art: Documentation&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">In today&rsquo;s day and age data is created at a rate of aproximaltelly 2.5 quintillion bytes per day[2] and this rate will continue to increase as the amount of technology that is used increases. With local machines not able to process data and deploy models fast enough, distributed computing has become a necessity.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Distributed computing has resulted in the creation of various systems that can scale out these computations into different nodes. &ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">I</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">n the open source Apache Hadoop stack, systems like Storm1 and Impala9 are also specialized. Even in the relational database world, the trend has been to move away from &ldquo;one-size-fits-all&rdquo; systems. Unfortunately, most big data applications need to combine many different processing types. Specialized engines can thus create both complexity and inefficiency; users must stitch together disparate systems, and some applications simply cannot be expressed efficiently in any engine</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">.&rdquo;[3]. In this context Apache Spark was created in order to create a unified engine.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">Apache Spark&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Apache Spark, was a project started in the University of California, Berkeley in 2009 in which a unified engine for distributed data processing was created. &ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">Using Resilient Distributed Datasets, RDDs, Spark can capture a wide range of processing workloads that previously needed separate engines</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&rdquo;.[4] Apache Spark has got four main libraries that run over the common engine: SparkSQL , Spark Streaming, MLlib and Graph X. Since Spark uses a unified API, applications are more easy to develop. Moreover, Spark can run various functions over the same data. One of the main components of Spark is that all the transformations are lazy,&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">6&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 7">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">meaning that they do not compute all the results right way. Instead the transformations are only computed when an action requires a result to be given to the driver program. Spark exposes RDD&rsquo;s through a functional programming in<br>&nbsp;Scala, Java, Python and R, where the user can use&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">local functions to run on the cluster.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The key of Spark is that even though all of these libraries run on the same engine it has got as good a response as specialized engines.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">In this project, we will use Spark in a new context that is Deep learning.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">Deep Learning Landscape Frameworks&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Deep learning like it was mentioned before, requires very big datasets and models that are computationally very heavy. In recent years, there has been an emergence of solutions that combine SparkandDeeplearning.Themostpopularframeworkswillbediscussedandas an objective of this project one will be chosen to be implemented.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">TensorflowOnSpark:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">It was developed by Yahoo for large-scale distributed deep learning on a Hadoop cluster in Yahoo&rsquo;s private cloud. It supports all of TensorFlow&rsquo;s functionalities and it&rsquo;s integrated with existing data and pipelines. It is an open source system that scales up with minimum changes in the code.[5]&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">CaffeonSpark&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">CaffeOnSpark is another Yahoo application of deep learning in Spark clusters. This framework is complementary to other non-deep learning libraries suchs as Spark SQL and&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">7&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">MLlib. This application supports neural network model training, testing and feature extraction and can be deployed in a private or public cloud.[6]&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">Elephas: Distributed DL with Keras and PySpark&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Elephas is an extension of Keras that allows the user to run distributed deep learning models at scale with Spark. Elphas supports the following applications: from parallel training of models to hyper-parameter optimization or distributed training of ensemble models by implementing algorithms on top of Keras using Sparks RDDs and data frames.[7]&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">BigDL&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">BidDL is another distributed deep learning library for Apache Spark. Modeled after Torch, BigDL provides support for deep learning including numeric computing via Tensor and high level neural networks. Moreover, users can load pretrained models from Caffe or Torch. It also uses Intel&rsquo;s Kernel library and parallel&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">computing techniques to achieve very high performance.[8]&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">Spark DL: Deep Learning Pipelines&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Deep Learning Pipelines is an open source library created by Databricks that provides high level APIs for scalable deep learning in Python with Apache Spark.[9] Built by the creators of Apache Spark, it is prepared to be merged into the official API. One of the main advantages of SparkDL is that it is very easy to implement, and it uses Tensorflow and Keras as its backend. This library builds on Apache Spark ML pipelines for the training of models and with Spark Dataframes and SQL for deploying the models[10]. It allows the user to apply pre-trained models as transformers in a Spark ML pipeline. It allows transfer learning as well as distributed hyperparameter tuning and the deployment of models in Data frames and SQL.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">As we can see there are many frameworks to work with deep learning in Spark. For this project we will try and implement SparkDL and in parallel we will implement the model in&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">8&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 9">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Amazon SageMaker. For the building of the models, transfer learning (discussed below) will be applied.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">Transfer Learning&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">One of the quickest ways to use deep learning is through transfer learning. Transfer learning is based on using pre-trained models from libraries like Keras and Tensorflow. These models have been trained in a particular dataset, so when applied to a new dataset they are not optimized. However, optimizing to the new dataset is much quicker than building up the model from scratch. Transfer learning is being used specifically in many cases like the one proposed for this project, cancer detection.[11]&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">AWS&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">For this project, we will be using Amazon Web Services to create our Spark clusters and storing our data.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">S3 buckets&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The data for this project will be stored in Amazon S3 buckets. S3 is an object storage service in which customers can store any amount of data. For this project the whole image dataset will be stored in S3 buckets.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">9&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 10">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">EMR Clusters and Jupyter Notebook&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">EMR is a cloud big data platform that allows us to use many tools like Apache Spark, Apache Hive, Apache HBase, Apache Hudi or Presto. It is a very easy to use application in which EMR notebooks can be deployed allowing users to collaborate in projects easily. For this project we will use an Amazon EMR Notebook, which is based on Jupyter Notebooks and it&rsquo;s designed for Apache Spark. It allows using languages like PySpark, SparkSQL, Spark R and Scala. [12]&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">Amazon Sagemaker&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Another technology that will be used for this project is Amazon SageMaker. It is a fully managed machine learning service that allows users to build and train machine and deep learning models. It provides an integrated Jupyter authoring notebook instance so that servers don&rsquo;t have to be managed. It also&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">provides common machine learning algorithms that are optimized to run in an efficient way in a distributed environment.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Amazon Sagemaker allows Spark on an<br> Amazon EMR. The SageMaker-Spark exists<br>&nbsp;to support Spark and Sagemaker integration in both directions. You can run Spark on an Amazon EMR and connect it to the SageMaker notebook where you can train models.[13]&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">10&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 11">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 24.000000pt; font-family: 'Economica'; font-weight: 700;">Description of Experiments&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">Objectives&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The objective of this project is to classify leukemic B-lymphoblast cells (cancer cells) from normal B-lymphoid precursors (healthy cells). In order to do so, we will build a deep learning classifier model.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">As we know, deep learning problems require a high computation power. Thus, the key of this project is to develop a deep learning image classifier in a distributed system. In order to do so, two approaches will be taken:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<ol style="list-style-type: decimal;">
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Building a deep learning model in Amazon SageMaker: We will build the image classifier in SageMaker using a Spark instance in the notebook. The model will be built using transfer learning and then it will be optimized for our data.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Build a deep learning model in a EMR Notebook with a Spark instance using a deep learning framework: We will build an image classifier to identify if a patient has cancer and needs treatment or if he is healthy using Tensorflow on a Spark instance created in an EMR notebook.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                </ol>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">In order to validate the results of our project we will test our models on unseen data and calculate the F1 score as our metric.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">Data Set Description&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">The dataset that will be used for this project was collected from a CodaLab[4] competition for classification of leukemic cells from normal cells in microscopic images.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">The dataset contains images of leukemic B-lymphoblast cells (malignant cells) and normal B-lymphoid cells. The data set has been preprocessed, as cells have been normalized and segmented from the original images. The images have a final size of roughly 300x300 pixels.[14]&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">11&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 12">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">The data is divided in two folders, one for training the model and one for testing. The complete data set is composed of images from 118 patients. In each folder there are cell images from each patient.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic; color: rgb(22.350000%, 22.350000%, 22.350000%);">Example of healthy(left) and malignant(right) cells from the data set.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">All the images names follow the following standard naming convention:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">UID_P_N_C_diagnosis&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<ul style="list-style-type: none;">
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'ArialMT'; color: rgb(22.350000%, 22.350000%, 22.350000%);">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">UID_</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">P</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">: P is the subject ID&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'ArialMT'; color: rgb(22.350000%, 22.350000%, 22.350000%);">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">UID_P_</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">N</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">: N is the number of image&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'ArialMT'; color: rgb(22.350000%, 22.350000%, 22.350000%);">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">UID_P_N_</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">C</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">:</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">C represents the cell count&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'ArialMT'; color: rgb(22.350000%, 22.350000%, 22.350000%);">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">UID_P_N_</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">diagnosis</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">:</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">all </span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">means cancer cell, </span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(22.350000%, 22.350000%, 22.350000%);">hem&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(22.350000%, 22.350000%, 22.350000%);">means healthy cell.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">Training Test set:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The dataset contains a total of 73 patients of which 47 have cancer and 26 are healthy. The separation of images in training and testing will be done by patients instead of by images of malignant and healthy cells. By doing so, we will not mix images from the same patient in the training and testing.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                </ul>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">12&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 13">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">Methodology&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The methodology followed in two experiments that were conducted will be explained below, with the problems encountered and how they were resolved.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">A. Sagemaker Experiment:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">For this experiment, as it was mentioned before, the main objective was to create a deep learning classification model in a Spark instance using SageMaker. Transfer learning will be used instead of creating our own model from scratch. Therefore, we will need to do hyperparameter tuning to customize it to our data set of cancer cells.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">1. Creatingtrainingandvalidationsets:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The dataset used for this project contained images of both cancer and healthy cells from different patients. We first create a training and validation set from the original data by separating our images by patient id. This way 80% of the patients are stored in the training&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">set and 20% in the test set.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Once the images have been downloaded, they are stored in a RECORDIO format, that is the format needed for the majority of transfer learning models in SageMaker.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">After getting the images in the right format we upload them into the S3 bucket for the&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">project called Leukemia project.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">13&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 14">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">2. CreateanAmazonSageMakernotebookinstance&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Once we have the data stores in the S3 buckets we need to set up a SageMaker notebook instance with a Spark cluster. This process will be done following the AWS documentation and it includes the following[15][16] :&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<ol style="list-style-type: lower-latin;">
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Creating a notebook instance using Amazon EMR, we select a Spark cluster.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Store the data in S3 buckets&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(26.270000%, 26.270000%, 26.270000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Load the image classification model. SageMaker is a platform based on Docker&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">containers, thus every built-in algorithm is a Docker image already prepared with all the libraries that will be necessary. Since we are using transfer learning, which was explained in the documentation, we will use this algorithm as our model. However, we will have to use hyperparameter tuning to customize it to our data set.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                </ol>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">14&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 15">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; color: rgb(40.000000%, 40.000000%, 40.000000%);">3.&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">PullingthedatafromtheS3buckets<br></span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The images that were stored in the S3 bucket in RECORDIO format will be used for&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">the training and validation of the model.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; color: rgb(40.000000%, 40.000000%, 40.000000%);">4.&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">Training the parameters of the algorithm&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Since we are using transfer learning, we will need to customize the parameters of the model to fit our data. The hyperparameters that are specific to the image classification algorithm are:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<ul style="list-style-type: none;">
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Arial'; font-weight: 700;">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">Num_layers:&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">T</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">he number of layers (depth) for the network. We will use 50.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Arial'; font-weight: 700;">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">Num_training_samples: </span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">This is the number of training samples. In our case, once we separated the data in the training and testing, we were left&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">with 8530 samples in the training set.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Arial'; font-weight: 700;">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">Num_classes:&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">This is the total number of classes. In our case, two, cancer&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">and healthy cells.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Arial'; font-weight: 700;">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">Epochs:&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Number of training epochs.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Arial'; font-weight: 700;">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">Learning_rate: </span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The learning rate at which the algorithm gets to a solution.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">In our case we decided a learning rate of 0.01.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Arial'; font-weight: 700;">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">Mini_batch_size:&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The number of training samples used for each mini batch.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Since we are using distributed training, the number of samples per batch will be N*mini_batch_size where N is the number of hosts on which the training is running.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                </ul>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">15&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 16">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Different values for these parameters were tried and we ended up choosing the ones stated above in order to have a better accuracy at the same that we didn&rsquo;t increase the computation time excessively.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">After setting the training parameters we kick off the training and poll for status until the model training is completed. For example, the training can take between 10 to 12 minutes per each epoch on a<br>&nbsp;p2.xlarge machine.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The network should typically converge after 10 epochs.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">5. Trainingofthemodel&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Once the model parameters have been stated, we will train the model using Amazon SageMaker CreateTrainingJob API. In each epoch the model will randomly select portions of the dataset for each batch, instead of using the whole dataset in each epoch. This will improve the final performance of the model, though it will introduce a small variation in the training results. We will create a job that will train our model and then it will be published in production as an endpoint.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">16&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 17">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">With the Amazon CloudWatch Logs we will see all the training algorithm outputs. We will be able to see the information for the &lsquo;validation-accuracy&rsquo;. With this value we will be able to see if the model is suffering from overfitting.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">6. Deployingthemodel&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">In order to deploy the model we will need to take the following steps:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<ol style="list-style-type: lower-latin;">
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Host the model: we will create a SageMaker model from the training output.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Create an endpoint configuration: A SageMaker Endpoint is a fully managed service&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">that will allow us to make real-time inferences via a REST API.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Deploy the model using the endpoint configuration defined. SageMaker will create&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">an instance and deploy a docker container with the algorithm that we selected. Inside this docker container the model will be hosted. The instance that we will create is a m4.xlarge, as it is the one that is provided by AWS. In our case, we are just using one model for our endpoint but many more models can be used with the same endpoint.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The code for this part will be included in the appendix of the project. An endpoint is also monitored by CloudWatch so we can see information like the runtime logs, invocation metrics and instance metrics.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">7. Performrealtimeinference&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                </ol>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Once we have our model hosted, we will use it to make a prediction on a single image.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">17&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 18">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The model will be hosted for inference. The output of this will be the probability values for the classes encoded in JSON format. We will need to convert the JSON format into an array. Then, we will find the class with the maximum probability and we will print the class index.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">8. Create a batch transform job&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Batch transform will be used to perform a prediction in a big dataset or schedule. With all of our data in the S3 bucket, we will connect it to SageMaker which will start the batch transform job starting a new EC2 instance. This new instance will process all the data and return it back into the S3 bucket in addition to the inference done.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We created a batch establishing the parameters like the input and output location and the instance type, in our case p2.xlarge.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">18&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 19">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We create the transform job and we will be ready to perform the classification model on the images.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">19&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 20">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">9. ApplyclassificationmodeltotestdataandcalculateF1score&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We perform the prediction for our data, having a label of classification for each image. This will be stored in a data frame with the real label and the predicted label in order to obtain the F1 score. Since SageMaker does not provide this metric, we will have to calculate it with the confusion matrix. These results will be explained in more detail below in the results.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">B. Experiment using a deep learning framework&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">For this second experiment, we decided to use one of the existing deep learning frameworks. Upon reading documentation about the different possibilities available we decided to try and use the Databricks library SparkDL.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">1. SettingupEMRnotebookandinstallinglibraries:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">SparkDL like it was mentioned in the documentation section is a deep learning library that uses Keras and Tensorflow as its backend. It is also a library that uses transfer learning with pre-trained models with Spark and is available in both batch and streaming data processing. This library allows us to run single node models in a distributed fashion on large amounts of data.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">After creating an EMR notebook with a Spark instance, we needed to get the libraries installed in it. We used the new feature of EMR notebooks that allows us to install on a&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">20&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 21">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">running cluster. The installation happens on the notebook file, so that if we need to change clusters the library environment can be recreated. We were able to install both Keras and Tensorflow starting the kernel to PySpark as these libraries were part of the PyPi repository.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">However, when trying to get SparkDL installed into the notebook we runned into some issues. The SparkDL library version that can be installed into an EMR notebook is an outdated version that doesn&rsquo;t have all the modules necessary to work. Therefore, it was not possible for us to run in on a Spark EMR notebook. Also, many of the functions of the package are obsolete and no longer work. Having this problem that had no apparent solution, we decided to change the deep learning framework we would be using and decided to create our model using Tensorflow on Spark.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">2. ChangeofdeeplearningframeworkfromSparkDLtoTensorflow&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">In the previous step we installed all the libraries necessary using </span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">sc.install_pypi_package()&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">command including both Tensorflow and Keras. We will be using transfer learning with a pre-trained model of the Tensorflow library called ResNet50. This model is a CNN that has been previously trained for another image dataset. With a featurizer function we will peel off the last layer of the pre-trained CNN from ResNet50 and we will use the outputs of the previous layers as the features for a logistic regression algorithm. This logistic regression comes from the Spark package MLlib, which contains many machine learning algorithms to be used in Spark. With this method, the algorithm can converge using fewer images than building the model from the beginning.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">3. CreatingtheTrainingandTestSets&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Like in the previous experiment, we have all of our images inside an AWS S3 bucket. We need to pull these images from the bucket to create our training and testing sets. We used the MLlib function </span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">ImageSchema.readImages </span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">which allowed us to read the images from the S3 bucket into a Pyspark SQL dataframe.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">21&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 22">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We read the images into the schema and we add a label to show if the image belongs to a healthy category or if it belongs to the cancer category.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Now that we have all the images of both cancer and healthy cells in a data frame we need to merge them together so that we can separate the images by patient ID. This way as we did in the SageMaker model, we will have a training set containing a percentage of the patients and a testing containing the rest of the patients.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Once we have all the images with their classifying label, the patient ID and the number of cells in each image, we can do a bit of exploratory analysis to see how many images we have of each class.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">22&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 23">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We can see that we have 3389 images of healthy cells and 7272 images of cancer cells in our data set.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We can also count instead of the number of images that are healthy or malignant, we can see the number of patients that are healthy and those who are sick.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Finally, we can count the number of cells that the dataset contains depending if the patient is healthy or sick.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We can see how we have a larger cell count if the patient has cancer (label 0) than if the patient is healthy.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We will split our patients in 80-20% for the training and test sets.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">23&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 24">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">4. CreatingthemodelwithResNet50&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Once we have our training and testing sets, we will create our model for the transfer learning. Like it was mentioned before we will be using ResNet50 as our pre-trained model and then we will use the output of this pre-trained model as the features for a logistics regression.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">5. Creatingthefeatureswithafeaturizerfunction&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Once we have created our ReNet50 model we will need to preprocess our images so that they have the correct format. For this we will create a preprocess function that we will use for our images. We also create a featurizing function that will take the output of the ResNet50 model and return them as the features we will use for the logistic regression.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">24&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 25">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We create another featurize function using Pandas Scalar Iterator that will work iteratively so that we can work with batches of images. This will help us with the reducing training time as the model will not have to re-initialize every time the featurizing function is called.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Once we have defined the functions, we will create the features for the training set.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">6. Creatingthelogisticregressionmodel&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">With these features we will use them in the fitting of the logistic regression model.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'TrebuchetMS'; font-weight: 700; color: rgb(40.000000%, 40.000000%, 40.000000%);">7. Test model on testing set&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">With our logistic regression fit we can make predictions. We will see how the model behaves with new data from the testing set and we will calculate the F1 score of this model.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">25&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 26">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 24.000000pt; font-family: 'Economica'; font-weight: 700;">Results and Conclusions&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">Results&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">In the section above the two experiments that were conducted were explained thoroughly. In this section, we will summarize the main results obtained, the problems encountered and we will extract some conclusions from the experiments of the project.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">A. SageMaker Experiment:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The SageMaker model had a run time of approximately two hours. In the training and validation of the model we got the following results:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We can see how our model had a very high accuracy for both the training and the validation sets. Taking into consideration that our dataset was unbalanced we confirm that using the accuracy metric is not the best metric to see our models performance. That is&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">why for our testing we calculate the confusion matrix to get the F1. We did not do this for the training since SageMaker does not return the F1 score of the model. Since for the testing the model was deployed we were able to calculate the F1 score of the testing.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">26&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 27">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Taking into consideration the results of the confusion matrix we calculated the accuracy and F1 obtaining:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<ul style="list-style-type: none;">
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Arial'; font-weight: 700;">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">Accuracy:&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">0</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">.507&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Arial'; font-weight: 700;">● &nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-weight: 700;">F1 Score: </span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">0.5084&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">We can see that this metric is much lower than that obtained in the training set. This could be for a number of various reasons, from overfitting of the model to the&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">training set and the unbalanced data. However, we were able to run a deep learning model in a Spark instance which was the objective of the project.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 12.000000pt; font-family: 'OpenSans'; font-weight: 700; color: rgb(54.900000%, 44.710000%, 32.160000%);">B. Tensorflow Experiment:&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">The Tensorflow experiment ran into some major problems from the get go. Firstly we had some problems when installing the deep learning framework that we planned on using, SparkDL. After changing to using Tensorflow we were able to get some work done as explained above. However, we ran into another major problem.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">In the methodology we described how we were going to create the features to input into the Logistic Regression model. However, we had a problem with this as the Pandas Scalar Iterator. This function has been depreciated, thus we were unable to featurize our images to create our inputs for the Logistics Regression model. Running the process without an iterator led to excessive ram consumption as the model had to be initialized at every call of the function which led to high training times and high ram consumption. Hence we decided to move away from the tensorflow implementation to focus on our Sage-maker implementation.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 18.000000pt; font-family: 'Economica'; font-weight: 700; color: rgb(21.180000%, 60.000000%, 65.880000%);">Project Outtakes&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">With this project we tried to explore the uses of Spark in a deep learning framework. In the beginning we planned on using an existing framework that ran on Spark to create a classification model that would tell us if a patient had cancer or was healthy. Working in a&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                    <li>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</li>
                </ul>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">27&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 28">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">distributed system with Deep Learning is a field which still has a lot of future work to be done as there are many functions that have problems working. We had a lot of problems trying to get various of the deep learning frameworks we found in the documentation to work properly. But we did learn that there are many options to work with deep learning in order to process images even if we were unable to implement the model as we would have wished.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">On the other hand, we used a new technology to us, Amazon SageMaker. With this project we had to learn how to use this new technology. We ran into some complications but in the end we were able to create a model and deploy it. The results we obtained were not extremely pleasing but that is due to the preparation of the data as we had an unbalanced data set. Nevertheless, it allowed us to explore a new technology and learn from it.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'Economica';">28&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 29">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 24.000000pt; font-family: 'Economica'; font-weight: 700;">References&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[1]Andreas Mainer, Christopher Syben, Tobias Lasser, Christian Riess, &ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">A gentle introduction to deep learning in medical image processing&rdquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">,</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Special Issue: Deep Learning in Medical Physics. May 2009&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[2]BernardMarr&ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">H</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">owmuchdatadowegenerateeveryday?Themind-blowingstatseveryone should read&rdquo;,&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">F</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">orbes Magazine&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[3] Matei Zaharia, Reynold S. Xin, Patrick Wndell, Tathagata Das, Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen Shivaram Venkataramn, Michael J Franklin, Ali Ghodsi, Joseph Gonzalez, Scott Shenker and Ion Stoica, &ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">A</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">pache Spark: A Unified Engine for Big Data Processing&rdquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">. Communications of the ACM Vol.59 No11, November 2016&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[4]Matei Zaharia, Reynold S. Xin, Patrick Wndell, Tathagata Das, Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen Shivaram Venkataramn, Michael J Franklin, Ali Ghodsi, Joseph Gonzalez, Scott Shenker and Ion Stoica, &ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">A</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">pache Spark: A Unified Engine for Big Data Processing&rdquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">. Communications of the ACM Vol.59 No11, November 2016&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[5]</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">y</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">ahoo/TensorFlowOnSpark: TensorFlowOnSpark brings TensorFlow programs to Apache Spark clusters.&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[6]&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">y</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">ahoo/CaffeOnSpark: Distributed deep learning on Hadoop and Spark clusters.&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[7]</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">m</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">axpumperla/elephas: Distributed Deep learning with Keras &amp; Spark<br></span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[8]</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">h</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">ttps://github.com/intel-analytics/BigDL<br></span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[9]</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">d</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">atabricks/spark-deep-learning:DeepLearningPipelinesforApacheSpark&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[10] Sue Ann Hong, Tim Hunter and Reynold Xin, &ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">A</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">Vision for making deep learning simple. From Machine learning practitioners to business analysts&rdquo; </span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Engineering Blog, June 6 2017&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[11] Dipanjan Sarkar, &ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">A</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in Deep Learning&rdquo;,&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">T</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">owardsdatascience.com, Nov 14 2018&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[12]</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">Run Jupyter Notebook and JupyterHub on Amazon EMR&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'Economica';">29&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp; &nbsp; &nbsp;</p>
<div class="page" title="Page 30">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<div class="layoutArea">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<div class="column">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[13] &ldquo;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; font-style: italic;">Amazon SageMaker for Machine Learning Deep Learning- a comprehensive guide&rdquo;&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">Medium. December 12 2019&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[14]</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">https://competitions.codalab.org/competitions/20395#learn_the_details-data-descriptio n&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[15]</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html&nbsp;</span><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[16]</span><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">https://aws.amazon.com/es/blogs/machine-learning/classify-your-own-images-using-a&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans'; color: rgb(6.670000%, 33.330000%, 80.000000%);">mazon-sagemaker/&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 24.000000pt; font-family: 'Economica'; font-weight: 700;">Appendix: Code&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<p><span style="font-size: 11.000000pt; font-family: 'OpenSans';">[17] big_data.pdf<br>&nbsp;[18] bigdataprojectviusalization.ipynb&nbsp;</span></p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</div>
<p>&nbsp; &nbsp;&nbsp;</p>
